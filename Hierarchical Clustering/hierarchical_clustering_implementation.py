# -*- coding: utf-8 -*-
"""Hierarchical Clustering Implementation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LMW00jtIlrchubtEY9eak4Djabyv0t1H
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn import datasets

# Import IRIS dataset
iris=datasets.load_iris()

iris_data=pd.DataFrame(iris.data)

iris_data.columns=iris.feature_names

iris_data

#standardisation -> always done
from sklearn.preprocessing import StandardScaler
scaler=StandardScaler()

X_scaled=scaler.fit_transform(iris_data)

X_scaled

# apply pca
from sklearn.decomposition import PCA

pca=PCA(n_components=2)

pca_scaled=pca.fit_transform(X_scaled)

plt.scatter(pca_scaled[:,0],pca_scaled[:,1],c=iris.target)

# apply agglometric clustering

#step 1 construct dendrogram
import scipy.cluster.hierarchy as sc
#plot the dendagram
plt.figure(figsize=(20,7))
plt.title("Dendograms")

#create dendrogram
sc.dendrogram(sc.linkage(pca_scaled,method='ward'))
plt.title("Dendrogram")
plt.xlabel("Sample Index")
plt.ylabel("Euclidean Distance")
plt.show()

from sklearn.cluster import AgglomerativeClustering
cluster=AgglomerativeClustering(n_clusters=2,linkage='ward') # affinity by default is euclidean
cluster.fit(pca_scaled)

cluster.labels_

plt.scatter(pca_scaled[:,0],pca_scaled[:,1],c=cluster.labels_)